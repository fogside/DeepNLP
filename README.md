# DeepNLP

## What had to be done:

0) ### *Intro* 
    * Neural networks, backprop, optimizers;
    * Tensorflow intro;
    * Mnist classification with logistic regression and MLP;

1) ### *Embeddings & Keras* 
    * Text classification: bag of words, TF-IDF
    * NLTK: lemmatization, stemming;
    * w2vec: skip gram & cbow;
    * fasttext, glove;
    * Intro to Keras;
    * Skip gram or CBOW with Keras;

2) ### *Convolutions* 
    * Text classification with embeddings;
    * Avito classification task;
    * (need to update)

3) ### *RNN* 
    * RNN,
    * backprop through time,
    * gradient explosion and vanishing,
    * LSTM & GRU, 
    * gradient clipping
    
4) ### *Seq2Seq*
    * Seq2Seq architecture
    * Attention mechanisms
    * Image Captioning
    * Modern architectures overview
    * (need to update)

## But what is really done:

0) ### *Intro* 
    * Neural networks, backprop, optimizers;
    * Tensorflow intro;
    * Mnist classification with logistic regression and MLP;

1) ### *Embeddings & Keras* 
    * Text classification: bag of words, TF-IDF
    * NLTK: lemmatization, stemming;
    * w2vec: skip gram & cbow;
    * fasttext;
    * Skip gram & CBOW with TF;
      * with minor bugs

2) ### *Convolutions* 
    * Intro to Keras;
    * 1D convolutions;
    * Avito classification task;

3) ### *RNN* 
    * vanilla RNN intro
    * names generation with RNN
