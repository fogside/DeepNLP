{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras + Tensorflow\n",
    "\n",
    "Tf очень мощная и крутая штука, но кодить на нем большие и сложные архитектуры не всегда оправданное занятие.\n",
    "\n",
    "На этот случай существует множество высокоуровневых фреймворков, под капотом которых работает Tensorflow:\n",
    "* [TFSlim](https://research.googleblog.com/2016/08/tf-slim-high-level-library-to-define.html)\n",
    "* [TFLearn](https://www.tensorflow.org/api_docs/python/tf/contrib/learn)\n",
    "* [Sonnet (deepMind)](https://github.com/deepmind/sonnet)\n",
    "* Keras\n",
    "\n",
    "Мы немного посмотрим на Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning!\n",
    "# ща тут данные начнут скачиваться, если их еще нет\n",
    "\n",
    "import numpy as np\n",
    "from mnist import load_dataset\n",
    "import keras\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "y_train,y_val,y_test = list(map(keras.utils.np_utils.to_categorical,[y_train,y_val,y_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0,0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Еще одно маленькое предисловие\n",
    "\n",
    "Keras позволяет имплементировать архитектуру deep-learning моделей такими высокоуровневыми абстракциями как `Dense layer with nonlinearity`, `dropout` или `batch normalization`.\n",
    "Keras даже берет на себя ответственность за правильную работу с `dropout` во время оценивания качества модели.\n",
    "\n",
    "Использовать один только Keras удобно, если речь идет о построении чего-то не очень замудренного вроде классификатора изображений.\n",
    "\n",
    "Но если архитектура предполагает совместное использование весовых матриц или `adversarial training` (и прочее похожее), то использование одного только high-level Keras'а становится затруднительным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(allow_growth=True,per_process_gpu_memory_fraction=0.1)\n",
    "s = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "import keras.layers as ll\n",
    "\n",
    "model = Sequential(name=\"cnn\")\n",
    "\n",
    "model.add(ll.InputLayer([1,28,28]))\n",
    "\n",
    "model.add(ll.Flatten())\n",
    "\n",
    "#network body\n",
    "model.add(ll.Dense(25))\n",
    "model.add(ll.Activation('linear'))\n",
    "\n",
    "model.add(ll.Dropout(0.9))\n",
    "\n",
    "model.add(ll.Dense(25))\n",
    "model.add(ll.Activation('linear'))\n",
    "\n",
    "#output layer: 10 neurons (for each class) with softmax\n",
    "model.add(ll.Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(\"adam\",\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model interface\n",
    "\n",
    "Модели в `Keras` используют тот же интерфейс fit/predict, что и модели в __Scikit-learn__.\n",
    "Давайте посмотрим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit(X,y) с автоматическим логгированием.\n",
    "model.fit(X_train, y_train, validation_data=(X_val,y_val), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посчитаем вероятности P(y|x)\n",
    "model.predict_proba(X_val[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save trained weights\n",
    "model.save(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLoss, Accuracy = \", model.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Упс..!\n",
    "\n",
    "Кажется, что с текущей архитектурой модель крайне неэффективна. Она даже не может побить результата линейной модели (val_acc ~0.92).\n",
    "\n",
    "Догадываешься почему?\n",
    "\n",
    "Здесь специально сделано пару ошибочек.\n",
    "\n",
    "Одна ошибочка мешает сетке выучить нелинейные зависимости, другая -- не дает ей выучить необходимое количество данных.\n",
    "\n",
    "Попробуй зафиксить обе ошибочки и поиграй с архитектурой пока не побьешь бейзлайны снизу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test score...\n",
    "test_predictions = model.predict_proba(X_test).argmax(axis=-1)\n",
    "test_answers = y_test.argmax(axis=-1)\n",
    "\n",
    "test_accuracy = np.mean(test_predictions==test_answers)\n",
    "\n",
    "print(\"\\nTest accuracy: {} %\".format(test_accuracy*100))\n",
    "\n",
    "assert test_accuracy>=0.92,\"Logistic regression can do better!\"\n",
    "assert test_accuracy>=0.975,\"Your network can do better!\"\n",
    "print(\"Great job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras + tensorboard\n",
    "\n",
    "Помнишь интерактивные графики от Tensorboard один ноутбук назад?\n",
    "\n",
    "Дело в том, что Keras может использовать Tensorboard, чтобы показать полезную информацию о ходе обучения.\n",
    "Давай посмотрим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential(name=\"cnn\")\n",
    "\n",
    "model.add(ll.InputLayer([1,28,28]))\n",
    "model.add(ll.Flatten())\n",
    "\n",
    "\n",
    "<Your architecture here>\n",
    "\n",
    "\n",
    "#output layer: 10 neurons for each class with softmax\n",
    "model.add(ll.Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(\"adam\",\"categorical_crossentropy\",metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "model.fit(X_train, y_train, validation_data=(X_val,y_val),epochs=1,\n",
    "          callbacks=[TensorBoard(\"./logs\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "port = 6000 + os.getuid()\n",
    "print(\"Port: %d\" % port)\n",
    "# !killall tensorboard\n",
    "os.system(\"tensorboard --logdir=./logs --port=%d &\" % port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quest For A Better Network\n",
    "Несколько советов о том, что ты можешь сделать со своей нейронкой;\n",
    "\n",
    "Советы очень общего характера и не относятся напрямую к решаемой в тетрадке задачке, но в целом они оч полезны.\n",
    "\n",
    " * __Размер имеет значение__\n",
    "   * MOAR neurons, \n",
    "   * MOAR layers, ([docs](https://keras.io/))\n",
    "\n",
    "   * Нелинейности -- функции активации могут быть разными:\n",
    "     * tanh, relu, leaky relu, etc\n",
    "   * Чем больше сетка, тем больше эпох ей нужно чтобы обучиться. Из этого вывод -- не стоит выбрасывать свою нейронку сразу, если после 5-ти эпох она все еще не обогнала бейзлайн (SPOILER!: на самом деле бейзлайн можно обогнать и за 3 эпохи:) )\n",
    "   * Ph'nglui mglw'nafh Cthulhu R'lyeh wgah'nagl fhtagn!\n",
    "\n",
    "\n",
    " * __Convolution layers__\n",
    "   * Это __must have__ пока у вас нет других супер идей\n",
    "   * `keras.layers.Conv2D`\n",
    "   * Warning! Сверточные сети тренируются довольно долго, если не использовать gpu. Это нормально.\n",
    "     * Если ты на cpu, то рекомендуется использовать что-то не слишком мощное.\n",
    "     * В ином варианте можно запустить сеть обучаться на ночь и проверить результат утром.\n",
    "     * Сделайте разумные оценки размера слоев. Первоначальная свертка с 128 нейронами, вероятно, является оверкиллом.\n",
    "     * __Чтобы уменьшить количество вычислений__ на порядок жертвуя точностью, попробуй использовать параметр __stride__.\n",
    "     Пример: stride=2 вместо stride=1\n",
    "     делает свертку сдвигаясь не на одну ячейку, а не 2, таким образом на выходе свертка примерно в 4 раза меньше.\n",
    " \n",
    "   * Еще куча всяких слоев и архитектур может быть найдена тут\n",
    "     * batch normalization, pooling, etc\n",
    "     * Docs - https://keras.io/layers\n",
    "     \n",
    "     \n",
    "\n",
    " * __Early Stopping__\n",
    "   * Тренить 100 эпох несмотря ни на что это плохая идея.\n",
    "   * Какие-то сети сходятся за 5 эпох, другие через 500 эпох.\n",
    "   * Путь к успеху: остановка, когда скор на валидации через 10 итераций не становится лучше достигнутого максимума\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    " * __Игры с оптимизацией__ - \n",
    "   * rmsprop, nesterov_momentum, adam, adagrad и другие.\n",
    "     * Возможно имеет смысл потюнить learning rate/momentum и др параметры обучения: batch size, number of epochs..\n",
    " \n",
    " \n",
    " \n",
    " * __BatchNormalization__ FTW!(for the win)\n",
    "     * `keras.layers.normalization.BatchNormalization`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " * __Регуляризация__ чтобы избежать переобучения\n",
    "   * Добавьте L2 нормализацию весов модели в функцию лосса\n",
    "     * Смотреть - https://keras.io/regularizers/\n",
    "   * Dropout - хотя в данном примере он уже есть\n",
    "     * `keras.layers.Dropout`   \n",
    "     * Действительно ли дропаут делает сетку лучше? Проверить.\n",
    "   \n",
    "   \n",
    " * __Data augmemntation__ - запросто получить в 5 раз больший набор данных? -- иногда это возможно \n",
    "   * https://keras.io/preprocessing/image/\n",
    "   * Zoom-in+slice = move\n",
    "   * Rotate+zoom(для удаления черных полосок?)\n",
    "   * Любые другие манипуляции\n",
    "   * Простой путь к этому (using PIL/Image): \n",
    "     * ```from scipy.misc import imrotate,imresize```\n",
    "     * и немного slicing'а\n",
    "   * Оставайтесь реалистичными.\n",
    "   Как правило, нет смысла переворачивать собак вверх ногами, поскольку это не так, как вы обычно их видите."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
