{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import os\n",
    "\n",
    "#thanks Muammar \n",
    "PAD_ix=-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem & Dataset\n",
    "\n",
    "* We solve a problem of transribing english words.\n",
    "* word (sequence of letters) -> transcipt (sequence of phonemes)\n",
    "* The problem is, some letters correspond to several phonemes and others - to none.\n",
    "* We solve it through encoder-decoder recurrent neural networks\n",
    "* This architecture is generally about converting ANY sequence into ANY other sequence. It could even become president one day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"./train.csv\") as fin:\n",
    "    ids,words,transcripts = zip(*[line.split(',') for line in list(fin)[1:]])\n",
    "    words = [word+\"@\" for word in words]\n",
    "    transcripts = [[\"START\"]+ts[:-2].split()+[\"END\"] for ts in transcripts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word, trans in zip(words[:5],phonemes[:5]):\n",
    "    print word,':',trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "* Same as before, only now we do this separately for words and transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phonemes = list(set([token for ts in transcripts for token in ts]))\n",
    "phoneme_to_ix = {ph:i for i,ph in enumerate(phonemes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "letters = list(set([token for word in words for token in word]))\n",
    "letter_to_ix = {l:i for i,l in enumerate(letters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(map(len,transcripts),bins=25);\n",
    "\n",
    "# truncate names longer than MAX_LEN characters. \n",
    "MAX_LEN = min([60,max(list(map(len,transcripts)))])\n",
    "#ADJUST IF YOU ARE UP TO SOMETHING SERIOUS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into matrix of int32. Pad with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def as_matrix(sequences,token_to_i, max_len=None,PAX_ix=PAD_ix):\n",
    "    max_len = max_len or max(map(len,sequences))\n",
    "    \n",
    "    matrix = np.zeros((len(sequences),max_len),dtype='int8') -1\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = map(token_to_i.get,seq)[:max_len]\n",
    "        matrix[i,:len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print as_matrix(words[:10],letter_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = T.matrix('token sequence','int32')\n",
    "target_phonemes = T.matrix('target phonemes','int32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build NN\n",
    "\n",
    "You will be building a model that takes token sequence and predicts next token\n",
    "\n",
    "\n",
    "* iput sequence\n",
    "* one-hot / embedding\n",
    "* recurrent layer(s)\n",
    "* otput layer(s) that predict output probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import InputLayer,DenseLayer,EmbeddingLayer\n",
    "from lasagne.layers import RecurrentLayer,LSTMLayer,GRULayer,CustomRecurrentLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "##ENCODER\n",
    "l_in = lasagne.layers.InputLayer(shape=(None, None),input_var=input_sequence)\n",
    "l_mask = lasagne.layers.InputLayer(shape=(None, None),input_var=T.neq(input_sequence,-1))\n",
    "l_emb = lasagne.layers.EmbeddingLayer(l_in, len(letters), 40)\n",
    "l_rnn = lasagne.layers.GRULayer(l_emb,256,only_return_final=True,mask_input=l_mask)\n",
    "\n",
    "##DECODER\n",
    "transc_in = lasagne.layers.InputLayer(shape=(None, None),input_var=target_phonemes)\n",
    "transc_mask = lasagne.layers.InputLayer(shape=(None, None),input_var=T.neq(target_phonemes,-1))\n",
    "transc_emb = lasagne.layers.EmbeddingLayer(transc_in, len(phonemes), 50)\n",
    "transc_rnn = lasagne.layers.GRULayer(transc_emb,256,hid_init=l_rnn,mask_input=transc_mask)\n",
    "\n",
    "\n",
    "#flatten batch and time to be compatible with feedforward layers (will un-flatten later)\n",
    "transc_rnn_flat = lasagne.layers.reshape(transc_rnn, (-1,transc_rnn.output_shape[-1]))\n",
    "\n",
    "l_out = lasagne.layers.DenseLayer(transc_rnn_flat,len(phonemes),nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model weights\n",
    "weights = lasagne.layers.get_all_params(l_out,trainable=True)\n",
    "print weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network_output = lasagne.layers.get_output(l_out)\n",
    "network_output = <reshape to [batch_i, time_tick, number_of_phonemes] symbolically> \n",
    "#If you use dropout do not forget to create deterministic version for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_flat = network_output[:,:-1,:].reshape([-1,len(phonemes)])\n",
    "targets_flat = target_phonemes[:,1:].ravel()\n",
    "\n",
    "#do not count loss for '-1' tokens\n",
    "mask = T.nonzero(T.neq(targets_flat,-1))\n",
    "\n",
    "loss = T.nnet.categorical_crossentropy(predictions_flat[mask],targets_flat[mask])\n",
    "\n",
    "updates = lasagne.updates.adam(loss.mean(),weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#training\n",
    "train = theano.function([input_sequence, target_phonemes], loss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "#computing loss without training\n",
    "compute_cost = theano.function([input_sequence, target_phonemes], loss, allow_input_downcast=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generation\n",
    "\n",
    "Simple: \n",
    "* get initial context(seed), \n",
    "* predict next token probabilities,\n",
    "* sample next token, \n",
    "* add it to the context\n",
    "* repeat from step 2\n",
    "\n",
    "You'll get a more detailed info on how it works in the homework section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compile the function that computes probabilities for next token given previous text.\n",
    "\n",
    "network_output = <network output reshaped to [batch,tick,phoneme] format>\n",
    "\n",
    "last_word_probas = <a matrix [batch_i, n_phonemes], counting all phonemes>\n",
    "\n",
    "probs = <a function that predicts probabilities coming after the last token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_transcript(word,transcript_prefix = (\"START\",),END_phoneme=\"END\"\n",
    "                        temperature=1,sample=True):\n",
    "    \n",
    "    transcript = list(transcript_prefix)\n",
    "    while True:\n",
    "        next_phoneme_probs = <a vector of probabilities of the next token>\n",
    "        next_phoneme_probs = <maybe apply temperature>\n",
    "\n",
    "        if sample:\n",
    "            next_phoneme = <phoneme sampled with these probabilities (string character)>\n",
    "        else:\n",
    "            next_phoneme = <most likely phoneme>\n",
    "\n",
    "        transcript.append(next_phoneme)\n",
    "\n",
    "        if next_phoneme==END_phoneme:\n",
    "            break\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "Here you can tweak parameters or insert your generation function\n",
    "\n",
    "\n",
    "__Once something word-like starts generating, try increasing seq_length__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = np.array(words)\n",
    "transcripts = np.array(transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_batch(words,transcripts, batch_size):\n",
    "    \n",
    "    <sample random batch of words and transcripts>\n",
    "    <convert both into network-edible format (as_matrix)>\n",
    "    \n",
    "    return words_batch,transcripts_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Training ...\")\n",
    "\n",
    "\n",
    "#total N iterations\n",
    "n_epochs=100\n",
    "\n",
    "# how many minibatches are there in the epoch \n",
    "batches_per_epoch = 500\n",
    "\n",
    "#how many training sequences are processed in a single function call\n",
    "batch_size=10\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "\n",
    "    avg_cost = 0;\n",
    "    \n",
    "    for _ in tqdm(range(batches_per_epoch)):\n",
    "        \n",
    "        x,y = sample_batch(words,transcripts,batch_size)\n",
    "        avg_cost += train(x, y).mean()\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    print(\"Epoch {} average loss = {}\".format(epoch, avg_cost / batches_per_epoch))\n",
    "    for i in range(5):\n",
    "        ind = np.random.randint(len(words))\n",
    "        print words[ind],':', ' '.join(generate_transcript(words[ind],sample=False)[1:-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And now,\n",
    "* try lstm/gru\n",
    "* try several layers\n",
    "* try mtg cards\n",
    "* try your own dataset of any kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
