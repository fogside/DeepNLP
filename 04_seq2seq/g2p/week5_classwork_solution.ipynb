{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import os\n",
    "\n",
    "#thanks Muammar \n",
    "PAD_ix=-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem & Dataset\n",
    "\n",
    "* We solve a problem of transribing english words.\n",
    "* word (sequence of letters) -> transcipt (sequence of phonemes)\n",
    "* The problem is, some letters correspond to several phonemes and others - to none.\n",
    "* We solve it through encoder-decoder recurrent neural networks\n",
    "* This architecture is generally about converting ANY sequence into ANY other sequence. It could even become president one day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"./train.csv\") as fin:\n",
    "    ids,words,transcripts = zip(*[line.split(',') for line in list(fin)[1:]])\n",
    "    words = [word+\"@\" for word in words]\n",
    "    transcripts = [[\"START\"]+ts[:-2].split()+[\"END\"] for ts in transcripts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phonemes = list(set([token for ts in transcripts for token in ts]))\n",
    "phoneme_to_ix = {ph:i for i,ph in enumerate(phonemes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "letters = list(set([token for word in words for token in word]))\n",
    "letter_to_ix = {l:i for i,l in enumerate(letters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFsNBktRiOEiSWgwHSVLL/wdcLv2JG/0t5AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f51be917b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(map(len,transcripts),bins=25);\n",
    "\n",
    "# truncate names longer than MAX_LEN characters. \n",
    "MAX_LEN = min([60,max(list(map(len,transcripts)))])\n",
    "#ADJUST IF YOU ARE UP TO SOMETHING SERIOUS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into matrix of int32. Pad with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def as_matrix(sequences,token_to_i, max_len=None,PAX_ix=PAD_ix):\n",
    "    max_len = max_len or max(map(len,sequences))\n",
    "    \n",
    "    matrix = np.zeros((len(sequences),max_len),dtype='int8') -1\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = map(token_to_i.get,seq)[:max_len]\n",
    "        matrix[i,:len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32 37 36 47 45 30 35 35 26 23 -1 -1 -1 -1 -1]\n",
      " [34 36 45 30 26 28 36 30 37 28 23 -1 -1 -1 -1]\n",
      " [39 31 36 43 36 40 46 37 43 31 26 40 30 40 23]\n",
      " [27 26 35 30 36 23 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [40 44 30 45 26 35 26 27 23 -1 -1 -1 -1 -1 -1]\n",
      " [45 22 37 35 30 26 44 23 -1 -1 -1 -1 -1 -1 -1]\n",
      " [35 30 37 27 26 34 22 37 23 -1 -1 -1 -1 -1 -1]\n",
      " [25 22 41 28 26 41 23 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [31 30 37 32 40 36 37 23 -1 -1 -1 -1 -1 -1 -1]\n",
      " [27 42 26 43 23 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]]\n"
     ]
    }
   ],
   "source": [
    "print as_matrix(words[:10],letter_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = T.matrix('token sequence','int32')\n",
    "target_phonemes = T.matrix('target phonemes','int32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build NN\n",
    "\n",
    "You will be building a model that takes token sequence and predicts next token\n",
    "\n",
    "\n",
    "* iput sequence\n",
    "* one-hot / embedding\n",
    "* recurrent layer(s)\n",
    "* otput layer(s) that predict output probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import InputLayer,DenseLayer,EmbeddingLayer\n",
    "from lasagne.layers import RecurrentLayer,LSTMLayer,GRULayer,CustomRecurrentLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "##ENCODER\n",
    "l_in = lasagne.layers.InputLayer(shape=(None, None),input_var=input_sequence)\n",
    "l_mask = lasagne.layers.InputLayer(shape=(None, None),input_var=T.neq(input_sequence,-1))\n",
    "l_emb = lasagne.layers.EmbeddingLayer(l_in, len(letters), 40)\n",
    "l_rnn = lasagne.layers.GRULayer(l_emb,256,only_return_final=True,mask_input=l_mask)\n",
    "\n",
    "##DECODER\n",
    "transc_in = lasagne.layers.InputLayer(shape=(None, None),input_var=target_phonemes)\n",
    "transc_mask = lasagne.layers.InputLayer(shape=(None, None),input_var=T.neq(target_phonemes,-1))\n",
    "transc_emb = lasagne.layers.EmbeddingLayer(transc_in, len(phonemes), 50)\n",
    "transc_rnn = lasagne.layers.GRULayer(transc_emb,256,hid_init=l_rnn,mask_input=transc_mask)\n",
    "\n",
    "\n",
    "#flatten batch and time to be compatible with feedforward layers (will un-flatten later)\n",
    "transc_rnn_flat = lasagne.layers.reshape(transc_rnn, (-1,transc_rnn.output_shape[-1]))\n",
    "\n",
    "l_out = lasagne.layers.DenseLayer(transc_rnn_flat,len(phonemes),nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, W, W_in_to_updategate, W_hid_to_updategate, b_updategate, W_in_to_resetgate, W_hid_to_resetgate, b_resetgate, W_in_to_hidden_update, W_hid_to_hidden_update, b_hidden_update, W_in_to_updategate, W_hid_to_updategate, b_updategate, W_in_to_resetgate, W_hid_to_resetgate, b_resetgate, W_in_to_hidden_update, W_hid_to_hidden_update, b_hidden_update, W, b]\n"
     ]
    }
   ],
   "source": [
    "# Model weights\n",
    "weights = lasagne.layers.get_all_params(l_out,trainable=True)\n",
    "print weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network_output = lasagne.layers.get_output(l_out)\n",
    "network_output = network_output.reshape([target_phonemes.shape[0],target_phonemes.shape[1],-1])\n",
    "#If you use dropout do not forget to create deterministic version for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_flat = network_output[:,:-1,:].reshape([-1,len(phonemes)])\n",
    "targets = target_phonemes[:,1:].ravel()\n",
    "\n",
    "#do not count loss for '-1' tokens\n",
    "mask = T.nonzero(T.neq(targets,-1))\n",
    "\n",
    "loss = T.nnet.categorical_crossentropy(predictions_flat[mask],targets[mask])\n",
    "\n",
    "\n",
    "updates = lasagne.updates.adam(loss.mean(),weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#training\n",
    "train = theano.function([input_sequence, target_phonemes], loss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "#computing loss without training\n",
    "compute_cost = theano.function([input_sequence, target_phonemes], loss, allow_input_downcast=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generation\n",
    "\n",
    "Simple: \n",
    "* get initial context(seed), \n",
    "* predict next token probabilities,\n",
    "* sample next token, \n",
    "* add it to the context\n",
    "* repeat from step 2\n",
    "\n",
    "You'll get a more detailed info on how it works in the homework section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compile the function that computes probabilities for next token given previous text.\n",
    "\n",
    "#reshape back into original shape\n",
    "network_output = network_output.reshape((target_phonemes.shape[0],target_phonemes.shape[1],len(phonemes)))\n",
    "#predictions for next tokens (after sequence end)\n",
    "last_word_probas = network_output[:,-1]\n",
    "probs = theano.function([input_sequence,target_phonemes],last_word_probas,allow_input_downcast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_transcript(word,transcript_prefix = (\"START\",),t=1,sample=True):\n",
    "    \n",
    "    transcript = list(transcript_prefix)\n",
    "    while True:\n",
    "        \n",
    "        next_phoneme_probs = probs(as_matrix([word],letter_to_ix),as_matrix([transcript],phoneme_to_ix) ).ravel()\n",
    "        next_phoneme_probs = next_phoneme_probs**t / np.sum(next_phoneme_probs**t)\n",
    "\n",
    "        if sample:\n",
    "            next_phoneme = np.random.choice(phonemes,p=next_phoneme_probs) \n",
    "        else:\n",
    "            next_phoneme = phonemes[np.argmax(next_phoneme_probs)]\n",
    "\n",
    "        transcript.append(next_phoneme)\n",
    "\n",
    "        if next_phoneme==\"END\":\n",
    "            break\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['START', 'SH', 'P', 'IY', 'AH', 'Z', 'Z', 'START', 'B', 'OW', 'END']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_transcript(\"OLOLO@\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "Here you can tweak parameters or insert your generation function\n",
    "\n",
    "\n",
    "__Once something word-like starts generating, try increasing seq_length__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Умная мысля 2\n",
    "Имеет смысл не брать случайные слова, а сэмплить более качественно\n",
    "1) перемешаем номера примеров\n",
    "2) проходим по первым 100(batch_size) примерам, потом по вторым 100 ... и так до конца выборки\n",
    "\n",
    "повторять до победы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = np.array(words)\n",
    "transcripts = np.array(transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_batch(words,transcripts, batch_size):\n",
    "    \n",
    "    batch_ix = np.random.randint(0,len(words),size=batch_size)\n",
    "    words_batch=as_matrix(words[batch_ix],letter_to_ix) \n",
    "    transcripts_batch=as_matrix(transcripts[batch_ix],phoneme_to_ix)\n",
    "    return words_batch,transcripts_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.9.0-py2.py3-none-any.whl (42kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 1.8MB/s \n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.9.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:00<00:50,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:45<00:00, 13.41it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 average loss = 2.67409567991\n",
      "AMMANN@ : T AE N T AH N\n",
      "CAREMARK'S@ : K R AE K AH L AH N\n",
      "LONELINESS@ : K AH N S AH N Z\n",
      "SHEILS@ : R AY D\n",
      "VERBALLY@ : F R AE K AH L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:44<00:00, 12.13it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 average loss = 1.96144024289\n",
      "CLAUDINA@ : L AE K S AH N Z\n",
      "SMITH@ : S T AE M\n",
      "BENIGNA@ : B IH NG G AH N\n",
      "MUTCH@ : M OW T\n",
      "HANDIER@ : HH AE N D ER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:44<00:00, 11.12it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 average loss = 1.52832217091\n",
      "ORDAINING@ : AA R AH L IH NG\n",
      "HOVERS@ : HH AE T ER Z\n",
      "CHATIHACHI@ : CH AE CH AH JH IY\n",
      "CREDITABLE@ : K R IY V AH B AH L\n",
      "UNTREATED@ : AH N T ER B AH L D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:47<00:00, 10.55it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 average loss = 1.26334943656\n",
      "GOEDERT@ : G AA D ER T\n",
      "FRANCORP@ : F R AA N T ER\n",
      "HOEPNER@ : HH AA P ER N\n",
      "NYBORG@ : N AA B AA R OW\n",
      "SPROUTAPHILE@ : S P R OW F AH L T IH Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:46<00:00,  4.34it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 average loss = 1.0987205949\n",
      "BEDORE@ : B EH D R OW\n",
      "MODALITIES@ : M AH D AH L T IH K S\n",
      "GALLER@ : G AE L ER\n",
      "SHASHLIK@ : SH AE S K AH L\n",
      "DUSTMAN@ : D AH S T AH M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:45<00:00, 12.61it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 average loss = 0.962769228037\n",
      "HOLMQUIST@ : HH OW L M P R IY T S\n",
      "STRESSES@ : S T R EH S IH Z\n",
      "WHARF@ : W AO R F\n",
      "BEHRENS@ : B ER G N Z\n",
      "INCANT@ : IH N K AE N T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:44<00:00, 11.26it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 average loss = 0.877662117702\n",
      "GOTSHALL@ : G AA T W AH L\n",
      "DANBY@ : D AE N B IY\n",
      "INNATE@ : IH N EY T IY\n",
      "TRUMBLE@ : T R AE M B AH L\n",
      "CONTINGENCIES@ : K AA N T IH N AH T IH N S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:46<00:00, 11.09it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 average loss = 0.797939463123\n",
      "BOUT@ : B OW T\n",
      "WIKLUND@ : W IH K L AH N D\n",
      "DARLEY@ : D AA R L IY\n",
      "TISHER@ : T AY SH ER\n",
      "SEEM@ : S IY M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:46<00:00, 10.92it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 average loss = 0.718155919214\n",
      "SHIFLETT@ : SH IH P L IH T\n",
      "PENSINGER@ : P EH N S IH NG ER\n",
      "GRAND'S@ : G R AE N D Z\n",
      "TEENA@ : T IY N AH\n",
      "MCLARTY@ : M AH K L AE R T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:43<00:00,  8.54it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 average loss = 0.685070049355\n",
      "XERISCAPE@ : S EH R IH S K EH P T AH\n",
      "LUMA@ : L UW M AH\n",
      "HOUSHOLDER@ : HH AW S HH AA L D ER\n",
      "DILIBERTO@ : D IH L IH B ER T OW\n",
      "DOKELY@ : D AA K AH L IY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:47<00:00, 10.59it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 average loss = 0.644432581514\n",
      "REVERSIBLE@ : R IH V ER S IY V\n",
      "UY@ : Y UW\n",
      "JAMMU'S@ : JH AE M AH S\n",
      "PRESIDENTS@ : P R EH Z IH D AH N T S\n",
      "LABOV@ : L AH B AA V\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:43<00:00, 11.09it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 average loss = 0.600716521165\n",
      "TIMUR@ : T IH M ER\n",
      "DESCHNER@ : D EH S M ER N\n",
      "GATZKE@ : G AE T S K IY\n",
      "BISSON@ : B IH S AH N\n",
      "CORNUCOPIA@ : K AO R N CH AA K OW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:44<00:00, 10.60it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 average loss = 0.589344962053\n",
      "CAPTAINING@ : K AE P AH N IH NG\n",
      "MONARCHY@ : M AA N ER IY\n",
      "HAGIOGRAPHY@ : HH AE G AH G AO R IY AH\n",
      "TEICHMANN@ : T IH K M AH N\n",
      "LUCENT@ : L UW S AH N T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:44<00:00, 11.14it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 average loss = 0.560619344801\n",
      "CYNRIC@ : S IH N R IH K\n",
      "FARLEY@ : F AA R L IY\n",
      "AY@ : EY\n",
      "BELLINO@ : B EH L IY N OW\n",
      "ENTREATY@ : EH N T R IY T IY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:42<00:00, 11.65it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 average loss = 0.528267260163\n",
      "OVERMYER@ : OW V ER M AY ER\n",
      "NEWCOM@ : N UW K AH M\n",
      "SCRUNCHED@ : S K R AH N CH T\n",
      "BOECKMANN@ : B OW K M AH N\n",
      "TED@ : T EH D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:45<00:00, 11.29it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 average loss = 0.515511607462\n",
      "CLEMMER@ : K L EH M ER\n",
      "OXIDIZE@ : AA K S AH D AY Z D\n",
      "VASBINDER@ : V AE S B IH N D ER\n",
      "ARBOTHNOTT@ : AA R B AA N T AE K T\n",
      "DIVERSIFYING@ : D IH V ER S IH F IH NG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:44<00:00,  9.85it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 average loss = 0.501669207193\n",
      "PACKET@ : P AE K AH T\n",
      "INVERNESS@ : IH N V ER N AH S\n",
      "BONSER@ : B AA N S ER\n",
      "GRUETZMACHER@ : G R UW T S K AA R\n",
      "FIELDCREST@ : F IY L D ER S T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:45<00:00, 10.91it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 average loss = 0.490789649643\n",
      "NOAH'S@ : N OW HH AA Z\n",
      "MARR@ : M AA R\n",
      "SIEWIOREK@ : S IY W ER IY\n",
      "SIMULATING@ : S IH M Y AH L EY T IH NG\n",
      "ENERGIZER@ : IH N ER JH AY ER Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:44<00:00, 11.30it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 average loss = 0.47286780201\n",
      "RECESSION@ : R IH S EH SH AH N\n",
      "KENNARD@ : K EH N ER D\n",
      "LIVESTOCK@ : L IH V IH S T AE K\n",
      "ROGSTAD@ : R AA G S T AE D\n",
      "TELECTRON@ : T EH L AH T R OW N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:50<00:00, 10.74it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 average loss = 0.463484897078\n",
      "NEWBROUGH@ : N UW B R OW\n",
      "D'ELECTRICITE@ : D IY L EH K T R IH K T IY\n",
      "ALTAMONT@ : AE L T AH M AH N T\n",
      "LOUISVILLE@ : L UW IH S AH V AH L\n",
      "MERCHANDISERS@ : M ER K AH N D AY Z ER Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:43<00:00, 11.38it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 average loss = 0.444196355364\n",
      "VAILE@ : V EY L\n",
      "MAHLMAN@ : M AA L M AH N\n",
      "SCHLESSINGER@ : SH L EH S IH N JH ER\n",
      "LANDHOLDING@ : L AE N D HH OW L D IH NG\n",
      "MONTBLANC@ : M AA N T B AE K S AH N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:45<00:00, 11.08it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 average loss = 0.438115408187\n",
      "VIRINA@ : V IH R IY N AH\n",
      "PODOLSKY@ : P OW D AA L S K IY\n",
      "GYPPED@ : JH IH P T\n",
      "STEAMY@ : S T IY M IY\n",
      "ANACOMP@ : AE N AH K AA M P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 147/500 [00:12<00:26, 13.44it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-0d7361f06711>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtranscripts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mavg_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/main/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    864\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/main/anaconda2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[0mallow_gc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_gc\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_gc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 953\u001b[1;33m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0m\u001b[0;32m    954\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m    955\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Training ...\")\n",
    "\n",
    "\n",
    "#total N iterations\n",
    "n_epochs=100\n",
    "\n",
    "# how many minibatches are there in the epoch \n",
    "batches_per_epoch = 500\n",
    "\n",
    "#how many training sequences are processed in a single function call\n",
    "batch_size=10\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "\n",
    "    avg_cost = 0;\n",
    "    \n",
    "    for _ in tqdm(range(batches_per_epoch)):\n",
    "        \n",
    "        x,y = sample_batch(words,transcripts,batch_size)\n",
    "        avg_cost += train(x, y).mean()\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    print(\"Epoch {} average loss = {}\".format(epoch, avg_cost / batches_per_epoch))\n",
    "    for i in range(5):\n",
    "        ind = np.random.randint(len(words))\n",
    "        print words[ind],':', ' '.join(generate_transcript(words[ind],sample=False)[1:-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['START', 'S', 'IY', 'F', 'S', 'IH', 'L', 'AH', 'N', 'END']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_transcript((\"zeppelin\"+\"@\").upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And now,\n",
    "* try lstm/gru\n",
    "* try several layers\n",
    "* try mtg cards\n",
    "* try your own dataset of any kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
